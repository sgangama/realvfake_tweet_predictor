{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the training dataset\n",
    "X1 = pd.read_excel('train.xlsx', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>genuinity</th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>Happy no one was hurt when #wmata train derail...</td>\n",
       "      <td>true</td>\n",
       "      <td>0.658669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>Deputies: Dog dispute leads to fatal shooting ...</td>\n",
       "      <td>true</td>\n",
       "      <td>0.523674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>Former Township fire truck being used in Phili...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.251757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>It's raining outside I'm burning my favorite c...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.297897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9547</th>\n",
       "      <td>Is this the end of AustraliaÂ‰Ã›Âªs best burge...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.789958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text genuinity    column\n",
       "id                                                                         \n",
       "3459  Happy no one was hurt when #wmata train derail...      true  0.658669\n",
       "5136  Deputies: Dog dispute leads to fatal shooting ...      true  0.523674\n",
       "5408  Former Township fire truck being used in Phili...      fake  0.251757\n",
       "1877  It's raining outside I'm burning my favorite c...      fake  0.297897\n",
       "9547  Is this the end of AustraliaÂ‰Ã›Âªs best burge...      fake  0.789958"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single out the text and the genuinity columns in your dataset as they are your feature and target labels\n",
    "data = X1[['text', 'genuinity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Souradipta Ganguly\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "3459    Happy no one was hurt when wmata train deraile...\n",
       "5136    Deputies Dog dispute leads to fatal shooting i...\n",
       "5408    Former Township fire truck being used in Phili...\n",
       "1877    Its raining outside Im burning my favorite can...\n",
       "9547    Is this the end of Australias best burger http...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert into lower case and remove junk characters so that our word vectors are free from additional discrepancies\n",
    "data['text'].apply(lambda x: x.lower()) #transform text to lowercase\n",
    "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         744,   41,   58,   23, 2382,   40, 1711,  118,  472,  287,    1,\n",
       "        1360,  389,    8,   29,  183,  419,   76, 1272, 1712],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        2841,  959, 1713,    4,  180,  594,    3,  611,  369],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  960,\n",
       "        1714,   42,  243,  121,  568,    3, 1182, 3496,  255],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,   35, 2842,  685,   31,   83,\n",
       "          12,  918, 4522,    6,  278,  177,    4, 3497,   90],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    8,   18,    1,  302,    5, 1715,  151,   50]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the words int the training dataset so that each portion of text is an embedding of a word vector\n",
    "#zero pad the sequences to maintain uniformity and avoid misreading of dataset\n",
    "tokenizer = Tokenizer(num_words=5000, split=\" \")\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X) # padding our text vector so they all have the same length\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a simple model\n",
    "#I would recommend using a more complex model like maybe increase the dense layers or incerase the dropout to improve \n",
    "#validation accuracy\n",
    "#you can also import the famous pretrained BERT model to gain the best results\n",
    "model=Sequential()\n",
    "model.add(Embedding(5000, 256, input_length=X.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 31, 256)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 31, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,331,138\n",
      "Trainable params: 2,331,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#we use the adam optimizer(rmsprop + momentum)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true and fake is converted into dummies like [0,1] and [1,0] so that proper mapping of inputs to labels can take place\n",
    "y = pd.get_dummies(data['genuinity']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "3459    true\n",
       "5136    true\n",
       "5408    fake\n",
       "1877    fake\n",
       "9547    fake\n",
       "Name: genuinity, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genuinity'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 - 39s - loss: 0.5465 - accuracy: 0.7254 - val_loss: 0.4750 - val_accuracy: 0.7741\n",
      "Epoch 2/10\n",
      "97/97 - 42s - loss: 0.3753 - accuracy: 0.8462 - val_loss: 0.4915 - val_accuracy: 0.7784\n",
      "Epoch 3/10\n",
      "97/97 - 43s - loss: 0.2947 - accuracy: 0.8803 - val_loss: 0.5487 - val_accuracy: 0.7668\n",
      "Epoch 4/10\n",
      "97/97 - 43s - loss: 0.2347 - accuracy: 0.9066 - val_loss: 0.6952 - val_accuracy: 0.7434\n",
      "Epoch 5/10\n",
      "97/97 - 43s - loss: 0.1864 - accuracy: 0.9290 - val_loss: 0.7935 - val_accuracy: 0.7405\n",
      "Epoch 6/10\n",
      "97/97 - 42s - loss: 0.1467 - accuracy: 0.9473 - val_loss: 0.8356 - val_accuracy: 0.7362\n",
      "Epoch 7/10\n",
      "97/97 - 44s - loss: 0.1085 - accuracy: 0.9580 - val_loss: 1.0333 - val_accuracy: 0.7347\n",
      "Epoch 8/10\n",
      "97/97 - 42s - loss: 0.1018 - accuracy: 0.9607 - val_loss: 1.1848 - val_accuracy: 0.7201\n",
      "Epoch 9/10\n",
      "97/97 - 42s - loss: 0.0810 - accuracy: 0.9666 - val_loss: 1.5575 - val_accuracy: 0.7187\n",
      "Epoch 10/10\n",
      "97/97 - 45s - loss: 0.0773 - accuracy: 0.9682 - val_loss: 1.3634 - val_accuracy: 0.7216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c232e7c788>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=2) #i used large batch size to quickly train the dataset. I would recommend that you choose your own allocation of data for better accuracy in predicions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can save the model so that you can import and use it again\n",
    "model.save('realvfake.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "#[print(data['text'][i], predictions[i], y_test[i]) for i in range(0, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9960369e-01, 3.9633826e-04], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true, real_true 332 310\n",
      "fake, real_fake 430 452\n"
     ]
    }
   ],
   "source": [
    "#initialize a simple counter to get a better idea of precision and recall i.e. false positives and false negatives and correctly\n",
    "#predicted values\n",
    "true, fake= 0,0\n",
    "real_true, real_fake = 0,0\n",
    "for i, prediction in enumerate(predictions):\n",
    "    if np.argmax(prediction)==1:\n",
    "        true+=1\n",
    "    else:\n",
    "        fake+=1\n",
    "    \n",
    "    if np.argmax(y_test[i])==1:\n",
    "        real_true+=1\n",
    "    else:\n",
    "        real_fake+=1\n",
    "\n",
    "print(\"true, real_true\", true, real_true)\n",
    "print(\"fake, real_fake\", fake, real_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=predictions.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the accuracy of your dataset i.e how accurately your validation set was predicted\n",
    "count = 0\n",
    "for i in range(0,len(predictions)-1):\n",
    "    if int(preds[i][0]) == y_test[i][0]:\n",
    "        count+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.7624671916010499\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = (count/len(preds))\n",
    "print(\"Val accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv') #load the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bata = test_data[['id','text']]  #single out the id and text as your input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                 Just happened a terrible car crash\n",
       "1   2  Heard about #earthquake is different cities, s...\n",
       "2   3  there is a forest fire at spot pond, geese are...\n",
       "3   9           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   28,  881,    2, 1926,  122,   84],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,  451,   52,\n",
       "         244,    8, 1171, 2545,  600, 1984,  223],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   74,    8,    2,  181,   42,   16,  783, 3398,   21,  843,\n",
       "           1,  739,    7, 1411,  324,   91,   38],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  430, 3523, 1412],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  494,\n",
       "         746,  467, 4037,    3,  917,    6, 1127]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "#tokenize the test set based on your tokenizer from the training set word vector \n",
    "Z = tokenizer.texts_to_sequences(bata['text'].values)\n",
    "Z = pad_sequences(Z) # padding our text vector so they all have the same length\n",
    "Z[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model.predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dummies to a list of 0 and 1 where 0 is fake and 1 is a real tweet\n",
    "preds4=[]\n",
    "for i in preds2:\n",
    "    if i[0]>i[1]:\n",
    "        preds4.append(1)\n",
    "    else:\n",
    "        preds4.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5=pd.DataFrame(preds4)  #convert to dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     0\n",
       "2     0\n",
       "3     1\n",
       "4     0\n",
       "...  ..\n",
       "3258  0\n",
       "3259  1\n",
       "3260  0\n",
       "3261  1\n",
       "3262  0\n",
       "\n",
       "[3263 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5.to_csv('sub_probale2.csv') #save as csv and you can copy paste the id of the tweets into the csv file to get your sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
